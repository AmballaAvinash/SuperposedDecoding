{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bab95df-aaee-4554-9e05-adcabac01657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/avinashamballa/Desktop/Avinash/Github_Repo/Superposed_Decoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2417da57-ad2b-4644-a870-1cd110a485b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairscale==0.4.13\n",
      "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from fairscale==0.4.13) (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from fairscale==0.4.13) (1.24.3)\n",
      "Requirement already satisfied: filelock in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (4.12.0)\n",
      "Requirement already satisfied: sympy in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->fairscale==0.4.13) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->fairscale==0.4.13) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/avinashamballa/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sympy->torch>=1.8.0->fairscale==0.4.13) (1.3.0)\n",
      "Building wheels for collected packages: fairscale\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332103 sha256=95a890b3d2e29ce9597f564137743421bcff10f832177273a6e252405a88e92b\n",
      "  Stored in directory: /Users/avinashamballa/Library/Caches/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
      "Successfully built fairscale\n",
      "Installing collected packages: fairscale\n",
      "Successfully installed fairscale-0.4.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairscale==0.4.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119805f4-8589-4379-ad87-a7bad4c0e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# import evaluate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from eval import *\n",
    "from superposed.llama.metrics import *\n",
    "from superposed.llama.generation import Llama\n",
    "from superposed.llama.superposed_generation import SuperposedLlama\n",
    "from superposed.llama.tokenizer import Tokenizer\n",
    "from superposed.ngrams.ngram_models import make_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c15900-c8b8-46d9-a884-6842a391ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_device = torch.device(\"cuda:0\")\n",
    "tokenizer = Tokenizer('7B/tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9817d9a4-ad64-41c6-b87b-b1e422b836a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'alpha': 0.54, 'temp': 0.06, 'n_drafts': 3, 'prompt_len': 15, 'n_token_sample': 9, 'n_token_consider': 32000, 'mixing_method': 'sample_new_weights_with_score', 'smoothing': 'geom', 'sample_tokens': 0, 'sample_beams': 0, 'i_weights': [0.01, 0.04, 0.15, 0.18, 0.12], 'i_length': [1, 2, 3, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "param_file = \"params/p15_d3_mixed.json\"\n",
    "with open(param_file, \"r\") as f:\n",
    "    params = json.load(f)\n",
    "    print(f\"Parameters: {params}\")\n",
    "alpha = params[\"alpha\"]\n",
    "temp = params[\"temp\"]\n",
    "n_drafts = params[\"n_drafts\"]\n",
    "prompt_len = params[\"prompt_len\"]\n",
    "n_token_sample = params[\"n_token_sample\"]\n",
    "i_weights = params[\"i_weights\"]\n",
    "i_length = params[\"i_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c99098e-a38b-4c78-a0e9-8c80309830bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making bigram...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ngrams/ckpts-100k/b_d_final.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create ngram models\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[43mmake_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mngrams/ckpts-100k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbigram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfourgram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfivegram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msixgram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msevengram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Avinash/Github_Repo/Superposed_Decoding/superposed/ngrams/ngram_models.py:70\u001b[0m, in \u001b[0;36mmake_models\u001b[0;34m(ckpt_path, bigram, trigram, fourgram, fivegram, sixgram, sevengram)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bigram:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking bigram...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mckpt_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/b_d_final.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     71\u001b[0m       bigram \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     72\u001b[0m   bigram_model \u001b[38;5;241m=\u001b[39m NGram(bigram, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigram\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ngrams/ckpts-100k/b_d_final.pkl'"
     ]
    }
   ],
   "source": [
    "# Create ngram models\n",
    "ngrams = make_models(\"ngrams/ckpts-100k\", bigram=True, trigram=True, fourgram=True, fivegram=True, sixgram=True, sevengram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3331332-242c-4e98-9f11-58c6dc0ef581",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m weight_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7B/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSuperposedLlama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mweight_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tokenizer.model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msup_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmodel_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Avinash/Github_Repo/Superposed_Decoding/superposed/llama/superposed_generation.py:38\u001b[0m, in \u001b[0;36mSuperposedLlama.build\u001b[0;34m(ckpt_dir, tokenizer_path, max_seq_len, max_batch_size, device, model_parallel_size, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\n\u001b[1;32m     29\u001b[0m     ckpt_dir: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     36\u001b[0m ):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_parallel_is_initialized():\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_parallel_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:74\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     73\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[0;32m---> 74\u001b[0m     func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mis_initialized():\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1141\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1138\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m   1139\u001b[0m         init_method, rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1140\u001b[0m     )\n\u001b[0;32m-> 1141\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/distributed/rendezvous.py:231\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43m_get_env_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRANK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld_size\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query_dict:\n\u001b[1;32m    234\u001b[0m     world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/distributed/rendezvous.py:216\u001b[0m, in \u001b[0;36m_env_rendezvous_handler.<locals>._get_env_or_raise\u001b[0;34m(env_var)\u001b[0m\n\u001b[1;32m    214\u001b[0m env_val \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(env_var, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_val:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _env_error(env_var)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_val\n",
      "\u001b[0;31mValueError\u001b[0m: Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set"
     ]
    }
   ],
   "source": [
    "weight_path = \"7B/\"\n",
    "model = SuperposedLlama.build(ckpt_dir=weight_path, \n",
    "                         tokenizer_path=f'{weight_path}/tokenizer.model', \n",
    "                         max_seq_len=100, \n",
    "                         max_batch_size=32,\n",
    "                         device=sup_device,\n",
    "                         model_parallel_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b48c23-d6a3-43b1-ad4c-54524aacfda6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5093373b-bf76-47e3-8f99-1045b60f29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokenizer, encoding):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tokenizer (Any): Tokenizer\n",
    "        encoding (torch.Tensor): Encoding\n",
    "    Returns:\n",
    "        decoding (str)\n",
    "    \"\"\"\n",
    "    eos_locs = (encoding == tokenizer.eos_id).nonzero()\n",
    "    if len(eos_locs > 0):\n",
    "        encoding = encoding[:eos_locs[0]]\n",
    "    return tokenizer.decode(encoding.to(torch.int32).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18703b19-f3e9-46e4-ab1c-c6d3b403c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Hi my name is\",\n",
    "    \"The Seattle Seahawks were Super Bowl\",\n",
    "    \"Penguins are birds native to\"\n",
    "]\n",
    "tokenized_prompts = tokenizer.encode(prompts, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d39cd735-9480-4979-ac92-bbd470f75570",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m alive_gens, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msup_generate(prompt_tokens\u001b[38;5;241m=\u001b[39mtokenized_prompts, \n\u001b[1;32m      2\u001b[0m                                         smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeom\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                         max_gen_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m      4\u001b[0m                                         n_token_sample\u001b[38;5;241m=\u001b[39mn_token_sample,\n\u001b[1;32m      5\u001b[0m                                         alpha\u001b[38;5;241m=\u001b[39malpha, \n\u001b[1;32m      6\u001b[0m                                         temp\u001b[38;5;241m=\u001b[39mtemp,\n\u001b[1;32m      7\u001b[0m                                         n_drafts\u001b[38;5;241m=\u001b[39mn_drafts,\n\u001b[1;32m      8\u001b[0m                                         i_weights\u001b[38;5;241m=\u001b[39mi_weights,\n\u001b[1;32m      9\u001b[0m                                         i_length\u001b[38;5;241m=\u001b[39mi_length,\n\u001b[1;32m     10\u001b[0m                                         ngrams\u001b[38;5;241m=\u001b[39mngrams,\n\u001b[1;32m     11\u001b[0m                                         get_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m                                         penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "alive_gens, _ = model.sup_generate(prompt_tokens=tokenized_prompts, \n",
    "                                        smoothing=\"geom\",\n",
    "                                        max_gen_len=10, \n",
    "                                        n_token_sample=n_token_sample,\n",
    "                                        alpha=alpha, \n",
    "                                        temp=temp,\n",
    "                                        n_drafts=n_drafts,\n",
    "                                        i_weights=i_weights,\n",
    "                                        i_length=i_length,\n",
    "                                        ngrams=ngrams,\n",
    "                                        get_time=False,\n",
    "                                        penalty=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfefa793-e49e-483a-a504-5cc9e23f619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = alive_gens[0].reshape(len(prompts) * n_drafts, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5abf87ab-2ee0-4204-868b-1215abf0c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "my name\n",
      "is L\n",
      "inda,\n",
      "I am\n",
      "a \n",
      "40\n",
      "year old\n",
      "woman who\n"
     ]
    }
   ],
   "source": [
    "for i in gens:\n",
    "    print(decode(tokenizer, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dc3cc-baa5-468d-bdd1-827465bdeb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
